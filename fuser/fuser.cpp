// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.9
// ONNX IR version: 13
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
//#include <half.hpp>
#include "readTensorFromFile.h"
#include "fuser.h"
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

/*
 * Operand:           Concat
 * Name in ONNX file: Concat_0
 */
static inline void node_Concat_0( const float input_0[1][80][180][180], const float input_1[1][256][180][180], float output[1][336][180][180] )
{
	/* Concat */
	int64_t outputOffset;
	outputOffset = 0;
	for (int64_t i = 0, j = 0; i < 2592000; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_0 + i);
		if (++j == 2592000) {
			outputOffset += (8294400);
			j = 0;
		}
	}
	outputOffset = 2592000;
	for (int64_t i = 0, j = 0; i < 8294400; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_1 + i);
		if (++j == 8294400) {
			outputOffset += (2592000);
			j = 0;
		}
	}
}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_1
 */
static inline void node_Conv_1( const float x[1][336][180][180], const float w[256][336][3][3], const float bias[256], float y[1][256][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<336; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_2
 */
static inline void node_Relu_2( const float X[1][256][180][180], float Y[1][256][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<8294400; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_3
 */
static inline void node_Conv_3( const float x[1][256][180][180], const float w[128][256][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_4
 */
static inline void node_Relu_4( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_5
 */
static inline void node_Conv_5( const float x[1][128][180][180], const float w[128][128][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_6
 */
static inline void node_Relu_6( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_7
 */
static inline void node_Conv_7( const float x[1][128][180][180], const float w[128][128][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_8
 */
static inline void node_Relu_8( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_9
 */
static inline void node_Conv_9( const float x[1][128][180][180], const float w[128][128][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_10
 */
static inline void node_Relu_10( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_11
 */
static inline void node_Conv_11( const float x[1][128][180][180], const float w[128][128][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_12
 */
static inline void node_Relu_12( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_13
 */
static inline void node_Conv_13( const float x[1][128][180][180], const float w[128][128][3][3], const float bias[128], float y[1][128][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<128; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_14
 */
static inline void node_Relu_14( const float X[1][128][180][180], float Y[1][128][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<4147200; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_15
 */
static inline void node_Conv_15( const float x[1][128][180][180], const float w[256][128][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 2 2 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=2) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=2) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_16
 */
static inline void node_Relu_16( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_17
 */
static inline void node_Conv_17( const float x[1][256][90][90], const float w[256][256][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=90) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=90) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_18
 */
static inline void node_Relu_18( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_19
 */
static inline void node_Conv_19( const float x[1][256][90][90], const float w[256][256][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=90) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=90) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_20
 */
static inline void node_Relu_20( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_21
 */
static inline void node_Conv_21( const float x[1][256][90][90], const float w[256][256][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=90) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=90) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_22
 */
static inline void node_Relu_22( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_23
 */
static inline void node_Conv_23( const float x[1][256][90][90], const float w[256][256][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=90) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=90) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_24
 */
static inline void node_Relu_24( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_25
 */
static inline void node_Conv_25( const float x[1][256][90][90], const float w[256][256][3][3], const float bias[256], float y[1][256][90][90] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=-1; o0<90; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<90; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<256; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=90) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=90) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_26
 */
static inline void node_Relu_26( const float X[1][256][90][90], float Y[1][256][90][90] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<2073600; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_27
 */
static inline void node_Conv_27( const float x[1][128][180][180], const float w[256][128][1][1], const float bias[256], float y[1][256][180][180] )
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 1 1 
	 * pads: 0 0 0 0 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t o0=0, i0=0; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=0; o1<180; o1++, i1+=1) {
			y[b][m][o0][o1] = bias[m];
			for( int32_t c=0; c<128; c++ ) {
			for( uint32_t k0=0; k0<1; k0++ ) {
			for( uint32_t k1=0; k1<1; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				y[b][m][o0][o1] += x[b][c][ii0][ii1] *w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_28
 */
static inline void node_Relu_28( const float X[1][256][180][180], float Y[1][256][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<8294400; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           ConvTranspose
 * Name in ONNX file: ConvTranspose_29
 */
static inline void node_ConvTranspose_29( const float x[1][256][90][90], const float w[256][256][2][2], float y[1][256][180][180] )
{
	/* ConvTranspose
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 2 2 
	 * pads: 0 0 0 0 
	 * strides: 2 2 
	 * output_padding: 0 0 
	 * output_shape: 180 180 
	 * output_shape explicitly given in ONNX model: false
	 */
	memset(y, 0,33177600);

	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<256; m++) {
		for( int32_t i0=0; i0<90; i0++) {
		for( int32_t i1=0; i1<90; i1++) {
			for( int32_t c=0; c<256; c++ ) {
			for( int32_t k0=0, o0=i0*2-0; k0<2; k0++, o0+=1) {
			for( int32_t k1=0, o1=i1*2-0; k1<2; k1++, o1+=1) {
				if( o0<0) continue;
				if( o0>=180) continue;
				if( o1<0) continue;
				if( o1>=180) continue;
				y[b][m][o0][o1] += x[b][c][i0][i1] * w[c][m][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           BatchNormalization
 * Name in ONNX file: BatchNormalization_30
 */
static inline void node_BatchNormalization_30( const float X[1][256][180][180], const float scale[256], const float bias[256], const float mean[256], const float var[256], float output[1][256][180][180] )
{
	/* BatchNormalization
	 * epsilon = 0.0010000000474974513054
	 * momentum = 0.99000000953674316406
	 */

	for( int32_t b=0; b<1; b++ ) {
	for( int32_t c=0; c<256; c++ ) {
	for( uint32_t i2=0; i2<180; i2++ ) {
	for( uint32_t i3=0; i3<180; i3++ ) {
		float tmp_X = ( X[b][c][i2][i3] - mean[c] ) / ( var[c] );
		output[b][c][i2][i3] = tmp_X * scale[c] + bias[c];
	}
	}
	}
	}
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_31
 */
static inline void node_Relu_31( const float X[1][256][180][180], float Y[1][256][180][180] )
{
	/*Relu*/
	float *X_ptr = (float*)X;
	float *Y_ptr = (float*)Y;
	for( uint32_t i=0; i<8294400; i++ )
		Y_ptr[i] = X_ptr[i] > 0 ? X_ptr[i] : 0;

}

/*
 * Operand:           Concat
 * Name in ONNX file: Concat_32
 */
static inline void node_Concat_32( const float input_0[1][256][180][180], const float input_1[1][256][180][180], float output[1][512][180][180] )
{
	/* Concat */
	int64_t outputOffset;
	outputOffset = 0;
	for (int64_t i = 0, j = 0; i < 8294400; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_0 + i);
		if (++j == 8294400) {
			outputOffset += (8294400);
			j = 0;
		}
	}
	outputOffset = 8294400;
	for (int64_t i = 0, j = 0; i < 8294400; i++) {
		*((float*)output + (outputOffset + i)) = *((float*)input_1 + i);
		if (++j == 8294400) {
			outputOffset += (8294400);
			j = 0;
		}
	}
}


auto temp_parent_fuser_0_weight = read4DTensorFromFile<256,336,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.fuser.0.weight.txt");

auto temp_parent_fuser_0_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.fuser.0.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_0_weight = read4DTensorFromFile<128,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.0.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_0_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.0.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_3_weight = read4DTensorFromFile<128,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.3.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_3_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.3.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_6_weight = read4DTensorFromFile<128,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.6.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_6_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.6.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_9_weight = read4DTensorFromFile<128,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.9.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_9_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.9.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_12_weight = read4DTensorFromFile<128,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.12.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_12_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.12.bias.txt");

auto temp_parent_decoder_backbone_blocks_0_15_weight = read4DTensorFromFile<128,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.15.weight.txt");

auto temp_parent_decoder_backbone_blocks_0_15_bias = read1DTensorFromFile<128>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.0.15.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_0_weight = read4DTensorFromFile<256,128,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.0.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_0_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.0.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_3_weight = read4DTensorFromFile<256,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.3.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_3_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.3.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_6_weight = read4DTensorFromFile<256,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.6.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_6_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.6.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_9_weight = read4DTensorFromFile<256,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.9.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_9_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.9.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_12_weight = read4DTensorFromFile<256,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.12.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_12_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.12.bias.txt");

auto temp_parent_decoder_backbone_blocks_1_15_weight = read4DTensorFromFile<256,256,3,3>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.15.weight.txt");

auto temp_parent_decoder_backbone_blocks_1_15_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.backbone.blocks.1.15.bias.txt");

auto temp_parent_decoder_neck_deblocks_0_0_weight = read4DTensorFromFile<256,128,1,1>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.0.0.weight.txt");

auto temp_parent_decoder_neck_deblocks_0_0_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.0.0.bias.txt");

auto temp_parent_decoder_neck_deblocks_1_0_weight = read4DTensorFromFile<256,256,2,2>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.1.0.weight.txt");

auto temp_parent_decoder_neck_deblocks_1_1_weight = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.1.1.weight.txt");

auto temp_parent_decoder_neck_deblocks_1_1_bias = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.1.1.bias.txt");

auto temp_parent_decoder_neck_deblocks_1_1_running_mean = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.1.1.running_mean.txt");

auto temp_parent_decoder_neck_deblocks_1_1_running_var = read1DTensorFromFile<256>("/home/ting/SourceCode/BEVfusion-code/fuser/parent.decoder.neck.deblocks.1.1.running_var.txt");

union tensor_union_0 {
float tensor_510[1][336][180][180];
float tensor_512[1][256][180][180];
float tensor_514[1][128][180][180];
float tensor_516[1][128][180][180];
float tensor_518[1][128][180][180];
float tensor_520[1][128][180][180];
float tensor_522[1][128][180][180];
float tensor_524[1][128][180][180];
float tensor_538[1][256][180][180];
};

union tensor_union_1 {
float tensor_511[1][256][180][180];
float tensor_513[1][128][180][180];
float tensor_515[1][128][180][180];
float tensor_517[1][128][180][180];
float tensor_519[1][128][180][180];
float tensor_521[1][128][180][180];
float tensor_523[1][128][180][180];
float tensor_525[1][256][90][90];
float tensor_527[1][256][90][90];
float tensor_529[1][256][90][90];
float tensor_531[1][256][90][90];
float tensor_533[1][256][90][90];
float tensor_535[1][256][90][90];
float tensor_537[1][256][180][180];
float tensor_539[1][256][180][180];
float tensor_541[1][256][180][180];
};

union tensor_union_2 {
float tensor_526[1][256][90][90];
float tensor_528[1][256][90][90];
float tensor_530[1][256][90][90];
float tensor_532[1][256][90][90];
float tensor_534[1][256][90][90];
float tensor_536[1][256][90][90];
float tensor_540[1][256][180][180];
};

static union tensor_union_0 tu0;


static union tensor_union_1 tu1;


static union tensor_union_2 tu2;

static float tensor_parent_fuser_0_weight[256][336][3][3];

static float tensor_parent_fuser_0_bias[256];

static float tensor_parent_decoder_backbone_blocks_0_0_weight[128][256][3][3];

static float tensor_parent_decoder_backbone_blocks_0_0_bias[128];

static float tensor_parent_decoder_backbone_blocks_0_3_weight[128][128][3][3];

static float tensor_parent_decoder_backbone_blocks_0_3_bias[128];

static float tensor_parent_decoder_backbone_blocks_0_6_weight[128][128][3][3];

static float tensor_parent_decoder_backbone_blocks_0_6_bias[128];

static float tensor_parent_decoder_backbone_blocks_0_9_weight[128][128][3][3];

static float tensor_parent_decoder_backbone_blocks_0_9_bias[128];

static float tensor_parent_decoder_backbone_blocks_0_12_weight[128][128][3][3];

static float tensor_parent_decoder_backbone_blocks_0_12_bias[128];

static float tensor_parent_decoder_backbone_blocks_0_15_weight[128][128][3][3];

static float tensor_parent_decoder_backbone_blocks_0_15_bias[128];

static float tensor_parent_decoder_backbone_blocks_1_0_weight[256][128][3][3];

static float tensor_parent_decoder_backbone_blocks_1_0_bias[256];

static float tensor_parent_decoder_backbone_blocks_1_3_weight[256][256][3][3];

static float tensor_parent_decoder_backbone_blocks_1_3_bias[256];

static float tensor_parent_decoder_backbone_blocks_1_6_weight[256][256][3][3];

static float tensor_parent_decoder_backbone_blocks_1_6_bias[256];

static float tensor_parent_decoder_backbone_blocks_1_9_weight[256][256][3][3];

static float tensor_parent_decoder_backbone_blocks_1_9_bias[256];

static float tensor_parent_decoder_backbone_blocks_1_12_weight[256][256][3][3];

static float tensor_parent_decoder_backbone_blocks_1_12_bias[256];

static float tensor_parent_decoder_backbone_blocks_1_15_weight[256][256][3][3];

static float tensor_parent_decoder_backbone_blocks_1_15_bias[256];

static float tensor_parent_decoder_neck_deblocks_0_0_weight[256][128][1][1];

static float tensor_parent_decoder_neck_deblocks_0_0_bias[256];

static float tensor_parent_decoder_neck_deblocks_1_0_weight[256][256][2][2];

static float tensor_parent_decoder_neck_deblocks_1_1_weight[256];

static float tensor_parent_decoder_neck_deblocks_1_1_bias[256];

static float tensor_parent_decoder_neck_deblocks_1_1_running_mean[256];

static float tensor_parent_decoder_neck_deblocks_1_1_running_var[256];

void entry(float tensor_camera[1][80][180][180], float tensor_lidar[1][256][180][180], float tensor_middle[1][512][180][180]){
	node_Concat_0( tensor_camera, tensor_lidar, tu0.tensor_510);
	node_Conv_1( tu0.tensor_510, tensor_parent_fuser_0_weight, tensor_parent_fuser_0_bias, tu1.tensor_511);
	node_Relu_2( tu1.tensor_511, tu0.tensor_512);
	node_Conv_3( tu0.tensor_512, tensor_parent_decoder_backbone_blocks_0_0_weight, tensor_parent_decoder_backbone_blocks_0_0_bias, tu1.tensor_513);
	node_Relu_4( tu1.tensor_513, tu0.tensor_514);
	node_Conv_5( tu0.tensor_514, tensor_parent_decoder_backbone_blocks_0_3_weight, tensor_parent_decoder_backbone_blocks_0_3_bias, tu1.tensor_515);
	node_Relu_6( tu1.tensor_515, tu0.tensor_516);
	node_Conv_7( tu0.tensor_516, tensor_parent_decoder_backbone_blocks_0_6_weight, tensor_parent_decoder_backbone_blocks_0_6_bias, tu1.tensor_517);
	node_Relu_8( tu1.tensor_517, tu0.tensor_518);
	node_Conv_9( tu0.tensor_518, tensor_parent_decoder_backbone_blocks_0_9_weight, tensor_parent_decoder_backbone_blocks_0_9_bias, tu1.tensor_519);
	node_Relu_10( tu1.tensor_519, tu0.tensor_520);
	node_Conv_11( tu0.tensor_520, tensor_parent_decoder_backbone_blocks_0_12_weight, tensor_parent_decoder_backbone_blocks_0_12_bias, tu1.tensor_521);
	node_Relu_12( tu1.tensor_521, tu0.tensor_522);
	node_Conv_13( tu0.tensor_522, tensor_parent_decoder_backbone_blocks_0_15_weight, tensor_parent_decoder_backbone_blocks_0_15_bias, tu1.tensor_523);
	node_Relu_14( tu1.tensor_523, tu0.tensor_524);
	node_Conv_15( tu0.tensor_524, tensor_parent_decoder_backbone_blocks_1_0_weight, tensor_parent_decoder_backbone_blocks_1_0_bias, tu1.tensor_525);
	node_Relu_16( tu1.tensor_525, tu2.tensor_526);
	node_Conv_17( tu2.tensor_526, tensor_parent_decoder_backbone_blocks_1_3_weight, tensor_parent_decoder_backbone_blocks_1_3_bias, tu1.tensor_527);
	node_Relu_18( tu1.tensor_527, tu2.tensor_528);
	node_Conv_19( tu2.tensor_528, tensor_parent_decoder_backbone_blocks_1_6_weight, tensor_parent_decoder_backbone_blocks_1_6_bias, tu1.tensor_529);
	node_Relu_20( tu1.tensor_529, tu2.tensor_530);
	node_Conv_21( tu2.tensor_530, tensor_parent_decoder_backbone_blocks_1_9_weight, tensor_parent_decoder_backbone_blocks_1_9_bias, tu1.tensor_531);
	node_Relu_22( tu1.tensor_531, tu2.tensor_532);
	node_Conv_23( tu2.tensor_532, tensor_parent_decoder_backbone_blocks_1_12_weight, tensor_parent_decoder_backbone_blocks_1_12_bias, tu1.tensor_533);
	node_Relu_24( tu1.tensor_533, tu2.tensor_534);
	node_Conv_25( tu2.tensor_534, tensor_parent_decoder_backbone_blocks_1_15_weight, tensor_parent_decoder_backbone_blocks_1_15_bias, tu1.tensor_535);
	node_Relu_26( tu1.tensor_535, tu2.tensor_536);
	node_Conv_27( tu0.tensor_524, tensor_parent_decoder_neck_deblocks_0_0_weight, tensor_parent_decoder_neck_deblocks_0_0_bias, tu1.tensor_537);
	node_Relu_28( tu1.tensor_537, tu0.tensor_538);
	node_ConvTranspose_29( tu2.tensor_536, tensor_parent_decoder_neck_deblocks_1_0_weight, tu1.tensor_539);
	node_BatchNormalization_30( tu1.tensor_539, tensor_parent_decoder_neck_deblocks_1_1_weight, tensor_parent_decoder_neck_deblocks_1_1_bias, tensor_parent_decoder_neck_deblocks_1_1_running_mean, tensor_parent_decoder_neck_deblocks_1_1_running_var, tu2.tensor_540);
	node_Relu_31( tu2.tensor_540, tu1.tensor_541);
	node_Concat_32( tu0.tensor_538, tu1.tensor_541, tensor_middle);
}



float* fuser(float* tensor_camera_copy, float* tensor_lidar_copy){
	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 336; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_fuser_0_weight[i][j][k][l] = temp_parent_fuser_0_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_fuser_0_bias[i] = temp_parent_fuser_0_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_0_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_0_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_0_bias[i] = temp_parent_decoder_backbone_blocks_0_0_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_3_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_3_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_3_bias[i] = temp_parent_decoder_backbone_blocks_0_3_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_6_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_6_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_6_bias[i] = temp_parent_decoder_backbone_blocks_0_6_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_9_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_9_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_9_bias[i] = temp_parent_decoder_backbone_blocks_0_9_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_12_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_12_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_12_bias[i] = temp_parent_decoder_backbone_blocks_0_12_bias[i];
	}


	for (size_t i = 0; i < 128; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_0_15_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_0_15_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 128; ++i) {
		tensor_parent_decoder_backbone_blocks_0_15_bias[i] = temp_parent_decoder_backbone_blocks_0_15_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_0_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_0_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_0_bias[i] = temp_parent_decoder_backbone_blocks_1_0_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_3_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_3_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_3_bias[i] = temp_parent_decoder_backbone_blocks_1_3_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_6_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_6_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_6_bias[i] = temp_parent_decoder_backbone_blocks_1_6_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_9_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_9_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_9_bias[i] = temp_parent_decoder_backbone_blocks_1_9_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_12_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_12_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_12_bias[i] = temp_parent_decoder_backbone_blocks_1_12_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 3; ++k) {
				for (size_t l = 0; l < 3; ++l) {
					tensor_parent_decoder_backbone_blocks_1_15_weight[i][j][k][l] = temp_parent_decoder_backbone_blocks_1_15_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_backbone_blocks_1_15_bias[i] = temp_parent_decoder_backbone_blocks_1_15_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 128; ++j) {
			for (size_t k = 0; k < 1; ++k) {
				for (size_t l = 0; l < 1; ++l) {
					tensor_parent_decoder_neck_deblocks_0_0_weight[i][j][k][l] = temp_parent_decoder_neck_deblocks_0_0_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_neck_deblocks_0_0_bias[i] = temp_parent_decoder_neck_deblocks_0_0_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		for (size_t j = 0; j < 256; ++j) {
			for (size_t k = 0; k < 2; ++k) {
				for (size_t l = 0; l < 2; ++l) {
					tensor_parent_decoder_neck_deblocks_1_0_weight[i][j][k][l] = temp_parent_decoder_neck_deblocks_1_0_weight[i][j][k][l];
				}
			}
		}
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_neck_deblocks_1_1_weight[i] = temp_parent_decoder_neck_deblocks_1_1_weight[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_neck_deblocks_1_1_bias[i] = temp_parent_decoder_neck_deblocks_1_1_bias[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_neck_deblocks_1_1_running_mean[i] = temp_parent_decoder_neck_deblocks_1_1_running_mean[i];
	}


	for (size_t i = 0; i < 256; ++i) {
		tensor_parent_decoder_neck_deblocks_1_1_running_var[i] = temp_parent_decoder_neck_deblocks_1_1_running_var[i];
	}
    // 动态分配 tensor_camera 数组
    float (*tensor_camera)[80][180][180] = (float (*)[80][180][180]) malloc(1 * 80 * 180 * 180 * sizeof(float));
    if (tensor_camera == nullptr) {
        std::cerr << "Failed to allocate memory for tensor_camera" << std::endl;
        return nullptr;
    }
    // 初始化 ttensor_camera 
    for (int i = 0; i < 80; ++i) {
        for (int j = 0; j < 180; ++j) {
            for (int k = 0; k < 180; ++k) {
                (*tensor_camera)[i][j][k] = tensor_camera_copy[i * 180 * 180 + j * 180 + k];
            }
        }
    }

    // 动态分配 tensor_lidar 数组
    float (*tensor_lidar)[256][180][180] = (float (*)[256][180][180]) malloc(1 * 256 * 180 * 180 * sizeof(float));
    if (tensor_lidar == nullptr) {
        std::cerr << "Failed to allocate memory for tensor_lidar" << std::endl;
        free(tensor_camera);
        return nullptr;
    }
    // 初始化 tensor_lidar 数组为 1
    for (int i = 0; i < 256; ++i) {
        for (int j = 0; j < 180; ++j) {
            for (int k = 0; k < 180; ++k) {
                (*tensor_lidar)[i][j][k] = tensor_lidar_copy[i * 180 * 180 + j * 180 + k];
            }
        }
    }
    // 动态分配 tensor_middle 数组
    float (*tensor_middle)[512][180][180] = (float (*)[512][180][180]) malloc(1 * 512 * 180 * 180 * sizeof(float));
    if (tensor_middle == nullptr) {
        std::cerr << "Failed to allocate memory for tensor_middle" << std::endl;
        free(tensor_camera);
        free(tensor_lidar);  // 释放之前分配的内存
        return nullptr;
    }

    // 初始化 tensor_middle 数组 (例如，填充为0)
    memset(tensor_middle, 0, 1 * 512 * 180 * 180 * sizeof(float));

    // 调用 entry 函数
    entry(tensor_camera, tensor_lidar, tensor_middle);

    // 创建一个一维数组来存储结果并返回
    float* result = (float*)malloc(1 * 256 * 180 * 180 * sizeof(float));
    if (result == nullptr) {
        std::cerr << "Failed to allocate memory for result" << std::endl;
        free(tensor_camera);
        free(tensor_lidar);
        free(tensor_middle);
        return nullptr;
    }
    
    // 复制数据到一维数组
    memcpy(result, tensor_middle, 1 * 256 * 180 * 180 * sizeof(float));

    // 释放动态分配的内存
    free(tensor_camera);
    free(tensor_lidar); 
    free(tensor_middle);
    printf("************success**************\n");
	return result;
}

// int main() {
// 	float *tensor_camera = new float[1 * 80 * 180 * 180];
// 	float *tensor_lidar = new float[1 * 256 * 180 * 180];
// 	// 初始化
// 	for (size_t i = 0; i < 1 * 80 * 180 * 180; ++i) {
// 		tensor_camera[i] = 1.0f;
// 	}
// 	for (size_t i = 0; i < 1 * 256 * 180 * 180; ++i) {
// 		tensor_lidar[i] = 1.0f;
// 	}
// 	float *fuser_output = fuser(tensor_camera, tensor_lidar);
// 	if (fuser_output == nullptr) {
// 		printf("Failed to allocate memory for fuser_output\n");
// 		return 1;
// 	}
	
// 	// 正确访问一维数组中的元素
// 	// for (size_t i = 0; i < 256; ++i) {
// 	// 	for (size_t j = 0; j < 180; ++j) {
// 	// 		for (size_t k = 0; k < 180; ++k) {
// 	// 			size_t index = i * 180 * 180 + j * 180 + k;
// 	// 			printf("%f ", lidar_backbone_output[index]);
// 	// 		}
// 	// 	}
// 	// }
	
// 	// 释放内存
// 	free(fuser_output);
// 	return 0;
// }


