// This file is computer-generated by onnx2c 
// (TODO: add creating command line here)
// (TODO: print creation date here )

// ONNX model:
// produced by pytorch, version 1.10
// ONNX IR version: 13
// Model documentation: 
/*

*/

#include <float.h>
#include <math.h>
#include <stdbool.h>
#include <stdint.h>
#include <string.h>
// #include <half.hpp>
#include "readTensorFromFile.h"
#include <iostream>
#include <random>
#include <ctime>
#include <memory>
#include "camera_vtransform.h"
#include "pipe_comm.h"
#include "apis_c.h"
#include <torch/torch.h>

InterChiplet::PipeComm global_pipe_comm;
#define MAX(X,Y) ( X > Y ? X : Y)
#define MIN(X,Y) ( X < Y ? X : Y)
#define CLIP(X,L) ( MAX(MIN(X,L), -L) )

// 修改ModelParams结构体，使用动态内存分配
struct ModelParams {
    float tensor_0_weight[80][80][3][3];
    float tensor_0_bias[80];
    float tensor_3_weight[80][80][3][3];
    float tensor_3_bias[80];
    float tensor_6_weight[80][80][3][3];
    float tensor_6_bias[80];
    
    // 使用指针替代大型数组
    std::unique_ptr<float[]> tensor_7_data;
    std::unique_ptr<float[]> tensor_8_data;
    std::unique_ptr<float[]> tensor_9_data;
    std::unique_ptr<float[]> tensor_10_data;
    std::unique_ptr<float[]> tensor_11_data;
    
    // 定义访问器函数
    float& tensor_7(int b, int c, int h, int w) {
        return tensor_7_data[((b * 80 + c) * 360 + h) * 360 + w];
    }
    
    float& tensor_8(int b, int c, int h, int w) {
        return tensor_8_data[((b * 80 + c) * 360 + h) * 360 + w];
    }
    
    float& tensor_9(int b, int c, int h, int w) {
        return tensor_9_data[((b * 80 + c) * 180 + h) * 180 + w];
    }
    
    float& tensor_10(int b, int c, int h, int w) {
        return tensor_10_data[((b * 80 + c) * 180 + h) * 180 + w];
    }
    
    float& tensor_11(int b, int c, int h, int w) {
        return tensor_11_data[((b * 80 + c) * 180 + h) * 180 + w];
    }
    
    // 构造函数动态分配内存
    ModelParams() {
        memset(tensor_0_weight, 0, sizeof(tensor_0_weight));
        memset(tensor_0_bias, 0, sizeof(tensor_0_bias));
        memset(tensor_3_weight, 0, sizeof(tensor_3_weight));
        memset(tensor_3_bias, 0, sizeof(tensor_3_bias));
        memset(tensor_6_weight, 0, sizeof(tensor_6_weight));
        memset(tensor_6_bias, 0, sizeof(tensor_6_bias));
        
        // 动态分配内存
        tensor_7_data = std::make_unique<float[]>(1 * 80 * 360 * 360);
        tensor_8_data = std::make_unique<float[]>(1 * 80 * 360 * 360);
        tensor_9_data = std::make_unique<float[]>(1 * 80 * 180 * 180);
        tensor_10_data = std::make_unique<float[]>(1 * 80 * 180 * 180);
        tensor_11_data = std::make_unique<float[]>(1 * 80 * 180 * 180);
        
        // 初始化为0
        std::fill_n(tensor_7_data.get(), 1 * 80 * 360 * 360, 0.0f);
        std::fill_n(tensor_8_data.get(), 1 * 80 * 360 * 360, 0.0f);
        std::fill_n(tensor_9_data.get(), 1 * 80 * 180 * 180, 0.0f);
        std::fill_n(tensor_10_data.get(), 1 * 80 * 180 * 180, 0.0f);
        std::fill_n(tensor_11_data.get(), 1 * 80 * 180 * 180, 0.0f);
    }
};

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_0
 */
static inline void node_Conv_0(const float* x, const float w[80][80][3][3], const float bias[80], std::shared_ptr<ModelParams>& params)
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<80; m++) {
		for( int32_t o0=0, i0=-1; o0<360; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<360; o1++, i1+=1) {
			params->tensor_7(b, m, o0, o1) = bias[m];
			for( int32_t c=0; c<80; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=360) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=360) continue;
				int x_idx = ((b * 80 + c) * 360 + ii0) * 360 + ii1;
				params->tensor_7(b, m, o0, o1) += x[x_idx] * w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_1
 */
static inline void node_Relu_1(const float* X, float* Y)
{
	/*Relu*/
	uint32_t i;
	for( i=0; i<10368000; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;
}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_2
 */
static inline void node_Conv_2(const float* x, const float w[80][80][3][3], const float bias[80], float* y)
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 2 2 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<80; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=2) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=2) {
			int y_idx = ((b * 80 + m) * 180 + o0) * 180 + o1;
			y[y_idx] = bias[m];
			for( int32_t c=0; c<80; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=360) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=360) continue;
				int x_idx = ((b * 80 + c) * 360 + ii0) * 360 + ii1;
				y[y_idx] += x[x_idx] * w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_3
 */
static inline void node_Relu_3(const float* X, float* Y)
{
	/*Relu*/
	uint32_t i;
	for( i=0; i<2592000; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;
}

/*
 * Operand:           Conv
 * Name in ONNX file: Conv_4
 */
static inline void node_Conv_4(const float* x, const float w[80][80][3][3], const float bias[80], float* y)
{
	/* Conv
	 *
	 * auto_pad: NOTSET
	 * dilations: 1 1 
	 * group: 1
	 * kernel_shape: 3 3 
	 * pads: 1 1 1 1 
	 * strides: 1 1 
	 */
	for( uint32_t b=0; b<1; b++ ) {
	for( uint32_t m=0; m<80; m++) {
		for( int32_t o0=0, i0=-1; o0<180; o0++, i0+=1) {
		for( int32_t o1=0, i1=-1; o1<180; o1++, i1+=1) {
			int y_idx = ((b * 80 + m) * 180 + o0) * 180 + o1;
			y[y_idx] = bias[m];
			for( int32_t c=0; c<80; c++ ) {
			for( uint32_t k0=0; k0<3; k0++ ) {
			for( uint32_t k1=0; k1<3; k1++ ) {
				int ii0 = i0+k0 * 1;
				if( ii0<0) continue;
				if( ii0>=180) continue;
				int ii1 = i1+k1 * 1;
				if( ii1<0) continue;
				if( ii1>=180) continue;
				int x_idx = ((b * 80 + c) * 180 + ii0) * 180 + ii1;
				y[y_idx] += x[x_idx] * w[m][c][k0][k1];
			} /* k */
			} /* k */
			} /* c */
		} /* o */
		} /* o */
	} /* m */
	} /* b */
}

/*
 * Operand:           Relu
 * Name in ONNX file: Relu_5
 */
static inline void node_Relu_5(const float* X, float* Y)
{
	/*Relu*/
	uint32_t i;
	for( i=0; i<2592000; i++ )
		Y[i] = X[i] > 0 ? X[i] : 0;
}

// 初始化权重和偏置的函数
std::shared_ptr<ModelParams> init_tensors() {
    try {
        std::cout << "正在加载权重文件..." << std::endl;
        
        auto params = std::make_shared<ModelParams>();
        
        //获取$BENCHMARK_ROOT/BEVfusion-code/camera_vtransform/build/0.weight.txt
        std::string weight_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/0.weight.txt";
        // 初始化 tensor_0_weight
        auto temp_0_weight = read4DTensorFromFile<80,80,3,3>(weight_path);
        std::cout << "已加载 0.weight.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            for (size_t j = 0; j < 80; ++j) {
                for (size_t k = 0; k < 3; ++k) {
                    for (size_t l = 0; l < 3; ++l) {
                        params->tensor_0_weight[i][j][k][l] = temp_0_weight[i][j][k][l];
                    }
                }
            }
        }
        
        // 初始化 tensor_0_bias
        std::string bias_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/0.bias.txt";
        auto temp_0_bias = read1DTensorFromFile<80>(bias_path);
        std::cout << "已加载 0.bias.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            params->tensor_0_bias[i] = temp_0_bias[i];
        }
        
        // 初始化 tensor_3_weight
        weight_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/3.weight.txt";
        auto temp_3_weight = read4DTensorFromFile<80,80,3,3>(weight_path);
        std::cout << "已加载 3.weight.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            for (size_t j = 0; j < 80; ++j) {
                for (size_t k = 0; k < 3; ++k) {
                    for (size_t l = 0; l < 3; ++l) {
                        params->tensor_3_weight[i][j][k][l] = temp_3_weight[i][j][k][l];
                    }
                }
            }
        }
        
        // 初始化 tensor_3_bias
        bias_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/3.bias.txt";
        auto temp_3_bias = read1DTensorFromFile<80>(bias_path);
        std::cout << "已加载 3.bias.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            params->tensor_3_bias[i] = temp_3_bias[i];
        }
        
        // 初始化 tensor_6_weight
        weight_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/6.weight.txt";
        auto temp_6_weight = read4DTensorFromFile<80,80,3,3>(weight_path);
        std::cout << "已加载 6.weight.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            for (size_t j = 0; j < 80; ++j) {
                for (size_t k = 0; k < 3; ++k) {
                    for (size_t l = 0; l < 3; ++l) {
                        params->tensor_6_weight[i][j][k][l] = temp_6_weight[i][j][k][l];
                    }
                }
            }
        }
        
        // 初始化 tensor_6_bias
        bias_path = std::string(getenv("BENCHMARK_ROOT")) + "/camera_vtransform/6.bias.txt";
        auto temp_6_bias = read1DTensorFromFile<80>(bias_path);
        std::cout << "已加载 6.bias.txt" << std::endl;
        for (size_t i = 0; i < 80; ++i) {
            params->tensor_6_bias[i] = temp_6_bias[i];
        }
        
        std::cout << "所有权重和偏置加载完成" << std::endl;
        return params;
    } catch (const std::exception& e) {
        std::cerr << "错误: " << e.what() << std::endl;
        exit(1);
    }
}

void entry(std::shared_ptr<ModelParams>& params, float* tensor_feat_in, float* tensor_feat_out){
    float* feat_in_ptr = tensor_feat_in;
    float* feat_out_ptr = tensor_feat_out;
    
    node_Conv_0(feat_in_ptr, params->tensor_0_weight, params->tensor_0_bias, params);
    node_Relu_1(params->tensor_7_data.get(), params->tensor_8_data.get());
    node_Conv_2(params->tensor_8_data.get(), params->tensor_3_weight, params->tensor_3_bias, params->tensor_9_data.get());
    node_Relu_3(params->tensor_9_data.get(), params->tensor_10_data.get());
    node_Conv_4(params->tensor_10_data.get(), params->tensor_6_weight, params->tensor_6_bias, params->tensor_11_data.get());
    node_Relu_5(params->tensor_11_data.get(), feat_out_ptr);
}

torch::Tensor view_transform(torch::Tensor input) {
    // 假设 view transformation 通过简单的求平均值来模拟 (6, 32, 88, 80) -> (1, 32, 88, 80)
    // 实际上应该使用深度感知投影
    input = input.mean(0, true); // 6个视角的平均值 (1, 32, 88, 80)
    
    // 上采样到 (1, 32, 360, 360)
    input = torch::nn::functional::interpolate(input, 
                torch::nn::functional::InterpolateFuncOptions()
                .size(std::vector<int64_t>({360, 360}))
                .mode(torch::kBilinear)
                .align_corners(false));
    
    return input; // (1, 32, 360, 360)
}

float* camera_vtransform(float *tensor_input){
    std::cout << "程序开始执行..." << std::endl;
    torch::Tensor input = torch::from_blob(tensor_input, {6, 32, 88, 80}, torch::kFloat32);
    torch::Tensor bev_features = view_transform(input);
    // 3. 通过 1x1 卷积调整通道数 (32 -> 80)
    torch::nn::Conv2d conv1x1(torch::nn::Conv2dOptions(32, 80, 1));
    bev_features = conv1x1(bev_features);
    // 4. 形状转换 (确保符合 (1, 80, 360, 360))
    bev_features = bev_features.view({1, 80, 360, 360});
    // 5. 将 torch::Tensor 转换为 float*
    float* tensor_feat_in = bev_features.data_ptr<float>();

        
    // 初始化权重和偏置
    auto params = init_tensors();
    
    // 使用C++的随机数生成器
    std::random_device rd;
    std::mt19937 gen(rd());
    std::uniform_real_distribution<float> dis(-1.0f, 1.0f);
    
    // 声明输入和输出张量
    float *tensor_feat_out = (float*)malloc(1 * 80 * 180 * 180 * sizeof(float));
    
    // 调用处理函数
    entry(params, tensor_feat_in, tensor_feat_out);
    
    // 打印部分结果用于验证
    std::cout << "Output tensor sample values:" << std::endl;
    for(int i = 0; i < 5; i++) {
        std::cout << "tensor_feat_out[0][0][0][" << i << "] = " 
                << tensor_feat_out[i] << std::endl;
    }

    
    // 打印输入输出张量维度
    std::cout << "\nTensor dimensions:" << std::endl;
    std::cout << "Input tensor:  [1][80][360][360]" << std::endl;
    std::cout << "Output tensor: [1][80][180][180]" << std::endl;
    
    return tensor_feat_out;
}

int main(int argc, char** argv) {
    int idX = atoi(argv[1]);
    int idY = atoi(argv[2]);
    float* tensor_feat_in = (float*)malloc(6 * 32 * 88 * 80 * sizeof(float));
    // // 随机初始化输入数据
    // for(int c = 0; c < 6; c++) {
    //     for(int h = 0; h < 32; h++) {
    //         for(int w = 0; w < 88; w++) {
    //             for(int d = 0; d < 80; d++) {
    //                 tensor_feat_in[((c * 32 + h) * 88 + w) * 80 + d] = 1.0f;
    //             }
    //         }
    //     }
    // }
    long long unsigned int timeNow = 1;
    std::string fileName = InterChiplet::receiveSync(5, 5, idX, idY);
    global_pipe_comm.read_data(fileName.c_str(), tensor_feat_in, 6 * 32 * 88 * 80 * sizeof(float));
    long long int time_end = InterChiplet::readSync(timeNow, 5, 5, idX, idY, 6 * 32 * 88 * 80 * sizeof(float), 0);
    std::cout<<"--------------------------------"<<std::endl;
    float* camera_vtransform_output = camera_vtransform(tensor_feat_in);
    fileName = InterChiplet::sendSync(idX, idY, 5, 5);
    global_pipe_comm.write_data(fileName.c_str(), camera_vtransform_output, 1 * 80 * 180 * 180 * sizeof(float));
    time_end = InterChiplet::writeSync(time_end, idX, idY, 5, 5, 1 * 80 * 180 * 180 * sizeof(float), 0);
    return 0;
}